{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "filename = 'gogi_chats'\n",
    "messages = pd.read_csv(f'data/{filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_non_na(series: pd.Series) -> float:\n",
    "    as_numbers = pd.to_numeric(series, errors='coerce')\n",
    "    return as_numbers.dropna().mean()\n",
    "\n",
    "eval_dimensions = ['friendliness', 'helpfulness', 'clearness', 'astuteness', 'tactfulness']\n",
    "eval_agg_funcs = {dim: mean_non_na for dim in eval_dimensions}\n",
    "chats = messages[['conversation_id', 'message', *eval_dimensions]].groupby('conversation_id').agg(\n",
    "    {\n",
    "        **eval_agg_funcs,\n",
    "        'message': lambda x: list(x)\n",
    "    }\n",
    ").reset_index().rename(columns={'message': 'chat'})\n",
    "chats = chats.dropna(subset=eval_dimensions)\n",
    "chats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_chat(chat: List[str]) -> List[Tensor]:\n",
    "    return [\n",
    "        tokenizer(u, padding=True, truncation=True, return_tensors=\"pt\")['input_ids'].squeeze()\n",
    "        for u in chat\n",
    "    ]\n",
    "\n",
    "node_encodings = []\n",
    "for _, chat_row in chats.iterrows():\n",
    "    node_encodings.append(tokenize_chat(chat_row['chat']))\n",
    "\n",
    "torch.save(node_encodings, f'data/{filename}_node_encodings.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "edge_idxs = []\n",
    "for _, chat_row in chats.head(1).iterrows():\n",
    "    chat = chat_row['chat']\n",
    "\n",
    "    human_idxs = [i for i in range(0, len(chat), 2)]\n",
    "\n",
    "    chat_edges = []\n",
    "    chat_edges_idxs = []\n",
    "    for ui in range(len(chat)):\n",
    "        for uj in range(len(chat)):\n",
    "            if ui == uj:\n",
    "                continue\n",
    "\n",
    "            edge_type = [\n",
    "                ui > uj,\n",
    "                ui in human_idxs,\n",
    "                uj in human_idxs,\n",
    "            ]\n",
    "\n",
    "            chat_edges_idxs.append((ui, uj))\n",
    "            chat_edges.append(edge_type)\n",
    "    \n",
    "    edges.append(Tensor(chat_edges).bool())\n",
    "    edge_idxs.append(Tensor(chat_edges_idxs).T.long())\n",
    "\n",
    "torch.save(edges, f'data/{filename}_edges.pt')\n",
    "torch.save(edge_idxs, f'data/{filename}_edge_idxs.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Tensor(chats[eval_dimensions].values), f'data/{filename}_labels.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
