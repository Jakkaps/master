{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "filename = 'ratings'\n",
    "save_path = f\"../data/{filename}\"\n",
    "\n",
    "dimensions = [\"Tactfulness\", \"Helpfulness\", \"Clearness\", \"Astuteness\"]\n",
    "\n",
    "ratings = pd.read_csv(f'../data/{filename}.csv')\n",
    "ratings = ratings[ratings['Tactfulness'].notna()]\n",
    "ratings['chat'] = ratings['chat'].apply(ast.literal_eval)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "chats = ratings['chat'].tolist()\n",
    "\n",
    "max_sen_len = 0\n",
    "max_nodes = 0\n",
    "tokenized = []\n",
    "for c in chats:\n",
    "    t = model.tokenize(c)['input_ids']\n",
    "    max_sen_len = max(max_sen_len, t.size(1))\n",
    "    max_nodes = max(max_nodes, t.size(0))\n",
    "    tokenized.append(t)\n",
    "\n",
    "\n",
    "node_tensor = torch.zeros(len(tokenized), max_nodes, max_sen_len)\n",
    "for i, c in enumerate(tokenized): \n",
    "    p = F.pad(c, (0, max_sen_len - c.size(1), 0, max_nodes - c.size(0)))\n",
    "    node_tensor[i] = p\n",
    "\n",
    "node_tensor = node_tensor.long()\n",
    "torch.save(node_tensor, f\"{save_path}/nodes.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Tensor(ratings[dimensions].values)\n",
    "torch.save(Tensor(labels), f\"{save_path}/labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "def create_chat_graph(chat, max_edges):\n",
    "    human_idxs = [i for i in range(0, len(chat), 2)]\n",
    "\n",
    "    chat_edges = []\n",
    "    chat_edges_idxs = []\n",
    "    for ui in range(len(chat)):\n",
    "        for uj in range(len(chat)):\n",
    "            if ui == uj:\n",
    "                edge_type = [True, False, False, False]\n",
    "            else:\n",
    "                edge_type = [\n",
    "                    False,\n",
    "                    ui > uj,\n",
    "                    ui in human_idxs,\n",
    "                    uj in human_idxs,\n",
    "                ]\n",
    "\n",
    "            edge_type = sum(2**i for i, v in enumerate(reversed(edge_type)) if v)\n",
    "\n",
    "            chat_edges_idxs.append((ui, uj))\n",
    "            chat_edges.append(edge_type)\n",
    "        \n",
    "    chat_edges_pad = chat_edges + [0] * (max_edges - len(chat_edges))\n",
    "    chat_edges_idxs_pad = chat_edges_idxs + [(0, 0)] * (max_edges - len(chat_edges_idxs))\n",
    "    \n",
    "    return chat_edges_pad, chat_edges_idxs_pad\n",
    "\n",
    "\n",
    "max_edges = max_nodes**2\n",
    "\n",
    "edges = torch.zeros(len(chats), max_edges, dtype=torch.int32)\n",
    "edge_idxs = torch.zeros(len(chats), 2, max_edges, dtype=torch.int64)\n",
    "\n",
    "for i, c in enumerate(chats):\n",
    "   c_edges, c_edge_idxs = create_chat_graph(c, max_edges)\n",
    "\n",
    "   edges[i] = Tensor(c_edges)\n",
    "   edge_idxs[i] = Tensor(c_edge_idxs).T\n",
    "\n",
    "torch.save(edges, f\"{save_path}/edges.pt\")\n",
    "torch.save(edge_idxs, f\"{save_path}/edge_idxs.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
